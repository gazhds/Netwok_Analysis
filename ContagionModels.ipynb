{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import powerlaw as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from networkx.algorithms.community.quality import modularity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('LFM1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 7624 nodes and 27806 edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(G)\n",
    "G.degree['7237']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import EoN\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Parameters\n",
    "# beta = 0.2  # transmission rate\n",
    "# gamma = 0.01  # recovery rate\n",
    "# initial_infected = [1] #starting point \n",
    "# G = nx.convert_node_labels_to_integers(G, first_label=0)\n",
    "\n",
    "# # Run the SIR model on the network\n",
    "# t, S, I, R = EoN.fast_SIR(G, beta, gamma, initial_infecteds = initial_infected)\n",
    "\n",
    "# # Plot the results\n",
    "# plt.plot(t, S, label='Susceptible')\n",
    "# plt.plot(t, I, label='Infected')\n",
    "# plt.plot(t, R, label='Recovered')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Number of nodes')\n",
    "# plt.title('SIR Model on Network')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do community discovery. We are going to use networkx module **community**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Label Propagation algorithm\n",
    "# import community\n",
    "communities_lp = nx.algorithms.community.label_propagation.label_propagation_communities(G)\n",
    "communities_louvain = nx.algorithms.community.louvain_communities(G)\n",
    "communities_greedy_mod = nx.algorithms.community.greedy_modularity_communities(G)\n",
    "\n",
    "# Convert communities to a list for better visualization\n",
    "communities_list_lp = [list(community) for community in communities_lp]\n",
    "communities_list_louvain = [list(community) for community in communities_louvain]\n",
    "communities_list_gm = [list(community) for community in communities_greedy_mod]\n",
    "\n",
    "# Print the detected communities\n",
    "# print(\"Detected Communities:\")\n",
    "# for i, community in enumerate(communities_list):\n",
    "#     print(f\"Community {i + 1}: {community}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "28\n",
      "44\n",
      "0.7522556757225006\n",
      "0.8157813971297904\n",
      "0.7955830887901616\n"
     ]
    }
   ],
   "source": [
    "print(len(communities_list_lp))\n",
    "print(len(communities_list_louvain))\n",
    "print(len(communities_list_gm))\n",
    "\n",
    "modularity_lp = modularity(G, communities_list_lp)\n",
    "modularity_louvain = modularity(G, communities_list_louvain) #the chosen one\n",
    "modularity_gm = modularity(G, communities_list_gm)\n",
    "print(modularity_lp)\n",
    "print(modularity_louvain)\n",
    "print(modularity_gm)\n",
    "#print modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1122, 1016, 929, 861, 666, 663, 500, 466, 271, 240, 197, 155, 126, 97, 70, 64, 60, 42, 13, 12, 11, 11, 7, 7, 5, 5, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# lengths_com = [(len(c)/7624)*100 for c in communities_list_louvain]\n",
    "lengths_com = [len(c) for c in communities_list_louvain]\n",
    "print(sorted(lengths_com, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(c) for c in communities_list_louvain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose louvain communities algorithm, because it gives highest modularity and a stable number of communities (read more about it). \n",
    "\n",
    "We saw there are some communities on the bottom that only contain 5-4 nodes, so we will ignore them (why? - think of good reason). \n",
    "\n",
    "So we take the top 16 communities, each containing more than 1% of the nodes in the network.\n",
    "\n",
    "From those we choose the biggest, smallest and middle one and see how the contagion spreads when we infect the nodes in them with highes degree/betweenness centrality. That should give us 3 different models. For each of them we will try several combinations of infection and recovery rate.\n",
    "\n",
    "We want to also see a random case in which we randomly choose a node/3 nodes from the network, regardless of community.\n",
    "\n",
    "OUR RESEARCH QUESTION: **Is the speed of the spread influenced by the size of the community associated with the initial node?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitation: not 100% likely that people will be in a single disjoint community; in future we are going to extend this to overlapping communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "sorted_communities = sorted(communities_list_louvain, key = len, reverse = True)\n",
    "result_dict = {i: sorted_communities[i] for i in range(1,len(sorted_communities))}\n",
    "merged_list = [item for sublist in sorted_communities[14:] for item in sublist]\n",
    "\n",
    "# Remove the first 16 key-value pairs\n",
    "for i in range(14,len(sorted_communities)):\n",
    "    result_dict.pop(i, None)\n",
    "\n",
    "# Add the merged list as the 17th key-value pair\n",
    "result_dict[14] = merged_list\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(len(result_dict[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = result_dict[1]\n",
    "B = result_dict[13]\n",
    "C = result_dict[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7237'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the largest community\n",
    "A_node_degree = {}\n",
    "for node in A:\n",
    "    A_node_degree[node] = G.degree(node)\n",
    "\n",
    "\n",
    "found_key_A = next((key for key, value in A_node_degree.items() if value == max(A_node_degree.values())), None)\n",
    "found_key_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3571'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the smalest community\n",
    "B_node_degree = {}\n",
    "for node in B:\n",
    "    B_node_degree[node] = G.degree(node)\n",
    "\n",
    "\n",
    "found_key_B = next((key for key, value in B_node_degree.items() if value == max(B_node_degree.values())), None)\n",
    "found_key_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5851'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without community\n",
    "C_node_degree = {}\n",
    "for node in C:\n",
    "    C_node_degree[node] = G.degree(node)\n",
    "\n",
    "\n",
    "found_key_C = next((key for key, value in C_node_degree.items() if value == max(C_node_degree.values())), None)\n",
    "found_key_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
